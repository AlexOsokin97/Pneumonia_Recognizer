{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.utils import normalize\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "broken img:  IM-0115-0001.jpeg\n",
      "broken img:  IM-0117-0001.jpeg\n",
      "broken img:  IM-0119-0001.jpeg\n",
      "broken img:  IM-0122-0001.jpeg\n",
      "broken img:  IM-0125-0001.jpeg\n",
      "broken img:  IM-0127-0001.jpeg\n",
      "broken img:  IM-0128-0001.jpeg\n",
      "broken img:  IM-0129-0001.jpeg\n",
      "broken img:  IM-0131-0001.jpeg\n",
      "broken img:  IM-0133-0001.jpeg\n",
      "broken img:  IM-0135-0001.jpeg\n",
      "broken img:  IM-0137-0001.jpeg\n",
      "broken img:  IM-0140-0001.jpeg\n",
      "broken img:  IM-0141-0001.jpeg\n",
      "broken img:  IM-0143-0001.jpeg\n",
      "broken img:  IM-0145-0001.jpeg\n",
      "broken img:  IM-0147-0001.jpeg\n",
      "broken img:  IM-0149-0001.jpeg\n",
      "broken img:  IM-0151-0001.jpeg\n",
      "broken img:  IM-0152-0001.jpeg\n",
      "broken img:  IM-0154-0001.jpeg\n",
      "broken img:  IM-0156-0001.jpeg\n",
      "broken img:  IM-0158-0001.jpeg\n",
      "broken img:  IM-0160-0001.jpeg\n",
      "broken img:  IM-0162-0001.jpeg\n",
      "broken img:  IM-0164-0001.jpeg\n",
      "broken img:  IM-0166-0001.jpeg\n",
      "broken img:  IM-0168-0001.jpeg\n",
      "broken img:  IM-0170-0001.jpeg\n",
      "broken img:  IM-0172-0001.jpeg\n",
      "broken img:  IM-0176-0001.jpeg\n",
      "broken img:  IM-0177-0001.jpeg\n",
      "broken img:  IM-0178-0001.jpeg\n",
      "broken img:  IM-0180-0001.jpeg\n",
      "broken img:  IM-0182-0001.jpeg\n",
      "broken img:  IM-0183-0001.jpeg\n",
      "broken img:  IM-0185-0001.jpeg\n",
      "broken img:  IM-0187-0001.jpeg\n",
      "broken img:  IM-0189-0001.jpeg\n",
      "broken img:  IM-0191-0001.jpeg\n",
      "broken img:  IM-0193-0001.jpeg\n",
      "broken img:  IM-0195-0001.jpeg\n",
      "broken img:  IM-0199-0001.jpeg\n",
      "broken img:  IM-0201-0001.jpeg\n",
      "broken img:  IM-0203-0001.jpeg\n",
      "broken img:  IM-0205-0001.jpeg\n",
      "broken img:  IM-0206-0001.jpeg\n",
      "broken img:  IM-0207-0001.jpeg\n",
      "broken img:  IM-0209-0001.jpeg\n",
      "broken img:  IM-0210-0001.jpeg\n",
      "broken img:  IM-0211-0001.jpeg\n",
      "broken img:  IM-0213-0001.jpeg\n",
      "broken img:  IM-0214-0001.jpeg\n",
      "broken img:  IM-0215-0001.jpeg\n",
      "broken img:  IM-0216-0001.jpeg\n",
      "broken img:  IM-0217-0001.jpeg\n",
      "broken img:  IM-0218-0001.jpeg\n",
      "broken img:  IM-0219-0001.jpeg\n",
      "broken img:  IM-0220-0001.jpeg\n",
      "broken img:  IM-0221-0001.jpeg\n",
      "broken img:  IM-0222-0001.jpeg\n",
      "broken img:  IM-0223-0001.jpeg\n",
      "broken img:  IM-0224-0001.jpeg\n",
      "broken img:  IM-0225-0001.jpeg\n",
      "broken img:  IM-0226-0001.jpeg\n",
      "broken img:  IM-0227-0001.jpeg\n",
      "broken img:  IM-0228-0001.jpeg\n",
      "broken img:  IM-0229-0001.jpeg\n",
      "broken img:  IM-0230-0001.jpeg\n",
      "broken img:  IM-0231-0001.jpeg\n",
      "broken img:  IM-0234-0001.jpeg\n",
      "broken img:  IM-0235-0001.jpeg\n",
      "broken img:  IM-0236-0001.jpeg\n",
      "broken img:  IM-0237-0001.jpeg\n",
      "broken img:  IM-0238-0001.jpeg\n",
      "broken img:  IM-0239-0001.jpeg\n",
      "broken img:  IM-0240-0001.jpeg\n",
      "broken img:  IM-0241-0001.jpeg\n",
      "broken img:  IM-0242-0001.jpeg\n",
      "broken img:  IM-0243-0001.jpeg\n",
      "broken img:  IM-0244-0001.jpeg\n",
      "broken img:  IM-0245-0001.jpeg\n",
      "broken img:  IM-0248-0001.jpeg\n",
      "broken img:  IM-0249-0001.jpeg\n",
      "broken img:  IM-0250-0001.jpeg\n",
      "broken img:  IM-0251-0001.jpeg\n",
      "broken img:  IM-0253-0001.jpeg\n",
      "broken img:  IM-0255-0001.jpeg\n",
      "broken img:  IM-0256-0001.jpeg\n",
      "broken img:  IM-0257-0001.jpeg\n",
      "broken img:  IM-0261-0001.jpeg\n",
      "broken img:  IM-0262-0001.jpeg\n",
      "broken img:  IM-0264-0001.jpeg\n",
      "broken img:  IM-0265-0001.jpeg\n",
      "broken img:  IM-0266-0001.jpeg\n",
      "broken img:  IM-0268-0001.jpeg\n",
      "broken img:  IM-0269-0001.jpeg\n",
      "broken img:  IM-0270-0001.jpeg\n",
      "broken img:  IM-0272-0001.jpeg\n",
      "broken img:  IM-0273-0001.jpeg\n",
      "broken img:  IM-0274-0001.jpeg\n",
      "broken img:  IM-0275-0001.jpeg\n",
      "broken img:  IM-0276-0001.jpeg\n",
      "broken img:  IM-0277-0001.jpeg\n",
      "broken img:  IM-0278-0001.jpeg\n",
      "broken img:  IM-0279-0001.jpeg\n",
      "broken img:  IM-0280-0001.jpeg\n",
      "broken img:  IM-0282-0001.jpeg\n",
      "broken img:  IM-0283-0001.jpeg\n",
      "broken img:  IM-0285-0001.jpeg\n",
      "broken img:  IM-0286-0001.jpeg\n",
      "broken img:  IM-0288-0001.jpeg\n",
      "broken img:  IM-0289-0001.jpeg\n",
      "broken img:  IM-0290-0001.jpeg\n",
      "broken img:  IM-0291-0001.jpeg\n",
      "broken img:  IM-0292-0001.jpeg\n",
      "broken img:  IM-0293-0001.jpeg\n",
      "broken img:  IM-0294-0001.jpeg\n",
      "broken img:  IM-0295-0001.jpeg\n",
      "broken img:  IM-0297-0001.jpeg\n",
      "broken img:  IM-0298-0001.jpeg\n",
      "broken img:  IM-0299-0001.jpeg\n",
      "broken img:  IM-0300-0001.jpeg\n",
      "broken img:  IM-0301-0001.jpeg\n",
      "broken img:  IM-0302-0001.jpeg\n",
      "broken img:  IM-0303-0001.jpeg\n",
      "broken img:  IM-0304-0001.jpeg\n",
      "broken img:  IM-0305-0001.jpeg\n",
      "broken img:  IM-0306-0001.jpeg\n",
      "broken img:  IM-0307-0001.jpeg\n",
      "broken img:  IM-0308-0001.jpeg\n",
      "broken img:  IM-0309-0001.jpeg\n",
      "broken img:  IM-0311-0001.jpeg\n",
      "broken img:  IM-0312-0001.jpeg\n",
      "broken img:  IM-0313-0001.jpeg\n",
      "broken img:  IM-0314-0001.jpeg\n",
      "broken img:  IM-0315-0001.jpeg\n",
      "broken img:  IM-0316-0001.jpeg\n",
      "broken img:  IM-0317-0001.jpeg\n",
      "broken img:  IM-0318-0001.jpeg\n",
      "broken img:  IM-0319-0001.jpeg\n",
      "broken img:  IM-0320-0001.jpeg\n",
      "broken img:  IM-0323-0001.jpeg\n",
      "broken img:  IM-0324-0001.jpeg\n",
      "broken img:  IM-0325-0001.jpeg\n",
      "broken img:  IM-0326-0001.jpeg\n",
      "broken img:  IM-0327-0001.jpeg\n",
      "broken img:  IM-0329-0001.jpeg\n",
      "broken img:  IM-0330-0001.jpeg\n",
      "broken img:  IM-0331-0001.jpeg\n",
      "broken img:  IM-0332-0001.jpeg\n",
      "broken img:  IM-0333-0001.jpeg\n",
      "broken img:  IM-0335-0001.jpeg\n",
      "broken img:  IM-0337-0001.jpeg\n",
      "broken img:  IM-0338-0001.jpeg\n",
      "broken img:  IM-0339-0001.jpeg\n",
      "broken img:  IM-0340-0001.jpeg\n",
      "broken img:  IM-0341-0001.jpeg\n",
      "broken img:  IM-0343-0001.jpeg\n",
      "broken img:  IM-0345-0001.jpeg\n",
      "broken img:  IM-0346-0001.jpeg\n",
      "broken img:  IM-0347-0001.jpeg\n",
      "broken img:  IM-0348-0001.jpeg\n",
      "broken img:  IM-0349-0001.jpeg\n",
      "broken img:  IM-0350-0001.jpeg\n",
      "broken img:  IM-0351-0001.jpeg\n",
      "broken img:  IM-0353-0001.jpeg\n",
      "broken img:  IM-0354-0001.jpeg\n",
      "broken img:  IM-0355-0001.jpeg\n",
      "broken img:  IM-0356-0001.jpeg\n",
      "broken img:  IM-0357-0001.jpeg\n",
      "broken img:  IM-0358-0001.jpeg\n",
      "broken img:  IM-0359-0001.jpeg\n",
      "broken img:  IM-0361-0001.jpeg\n",
      "broken img:  IM-0362-0001.jpeg\n",
      "broken img:  IM-0363-0001.jpeg\n",
      "broken img:  IM-0364-0001.jpeg\n",
      "broken img:  IM-0365-0001.jpeg\n",
      "broken img:  IM-0367-0001.jpeg\n",
      "broken img:  IM-0368-0001.jpeg\n",
      "broken img:  IM-0369-0001.jpeg\n",
      "broken img:  IM-0370-0001.jpeg\n",
      "broken img:  IM-0371-0001.jpeg\n",
      "broken img:  IM-0372-0001.jpeg\n",
      "broken img:  IM-0374-0001.jpeg\n",
      "broken img:  IM-0375-0001.jpeg\n",
      "broken img:  IM-0377-0001.jpeg\n",
      "broken img:  IM-0379-0001.jpeg\n",
      "broken img:  IM-0381-0001.jpeg\n",
      "broken img:  IM-0382-0001.jpeg\n",
      "broken img:  IM-0383-0001.jpeg\n",
      "broken img:  IM-0384-0001.jpeg\n",
      "broken img:  IM-0385-0001.jpeg\n",
      "broken img:  IM-0386-0001.jpeg\n",
      "broken img:  IM-0387-0001.jpeg\n",
      "broken img:  IM-0388-0001.jpeg\n",
      "broken img:  IM-0389-0001.jpeg\n",
      "broken img:  IM-0391-0001.jpeg\n",
      "broken img:  IM-0392-0001.jpeg\n",
      "broken img:  IM-0393-0001.jpeg\n",
      "broken img:  IM-0394-0001.jpeg\n",
      "broken img:  IM-0395-0001.jpeg\n",
      "broken img:  IM-0399-0001.jpeg\n",
      "broken img:  IM-0400-0001.jpeg\n",
      "broken img:  IM-0401-0001.jpeg\n",
      "broken img:  IM-0403-0001.jpeg\n",
      "broken img:  IM-0404-0001.jpeg\n",
      "broken img:  IM-0405-0001.jpeg\n",
      "broken img:  IM-0408-0001.jpeg\n",
      "broken img:  IM-0409-0001.jpeg\n",
      "broken img:  IM-0410-0001.jpeg\n",
      "broken img:  IM-0411-0001.jpeg\n",
      "broken img:  IM-0413-0001.jpeg\n",
      "broken img:  IM-0414-0001.jpeg\n",
      "broken img:  IM-0416-0001.jpeg\n",
      "broken img:  IM-0417-0001.jpeg\n",
      "broken img:  IM-0419-0001.jpeg\n",
      "broken img:  IM-0420-0001.jpeg\n",
      "broken img:  IM-0421-0001.jpeg\n",
      "broken img:  IM-0423-0001.jpeg\n",
      "broken img:  IM-0424-0001.jpeg\n",
      "broken img:  IM-0425-0001.jpeg\n",
      "broken img:  IM-0427-0001.jpeg\n",
      "broken img:  IM-0428-0001.jpeg\n",
      "broken img:  IM-0429-0001-0001.jpeg\n",
      "broken img:  IM-0429-0001-0002.jpeg\n",
      "broken img:  IM-0429-0001.jpeg\n",
      "broken img:  IM-0430-0001.jpeg\n",
      "broken img:  IM-0431-0001.jpeg\n",
      "broken img:  IM-0432-0001.jpeg\n",
      "broken img:  IM-0433-0001.jpeg\n",
      "broken img:  IM-0434-0001.jpeg\n",
      "broken img:  IM-0435-0001-0001.jpeg\n",
      "broken img:  IM-0435-0001.jpeg\n",
      "broken img:  IM-0437-0001-0001.jpeg\n",
      "broken img:  IM-0437-0001-0002.jpeg\n",
      "broken img:  IM-0437-0001.jpeg\n",
      "broken img:  IM-0438-0001.jpeg\n",
      "broken img:  IM-0439-0001-0001.jpeg\n",
      "broken img:  IM-0439-0001-0002.jpeg\n",
      "broken img:  IM-0439-0001.jpeg\n",
      "broken img:  IM-0440-0001.jpeg\n",
      "broken img:  IM-0441-0001.jpeg\n",
      "broken img:  IM-0442-0001.jpeg\n",
      "broken img:  IM-0444-0001.jpeg\n",
      "broken img:  IM-0445-0001.jpeg\n",
      "broken img:  IM-0446-0001.jpeg\n",
      "broken img:  IM-0447-0001.jpeg\n",
      "broken img:  IM-0448-0001.jpeg\n",
      "broken img:  IM-0449-0001.jpeg\n",
      "broken img:  IM-0450-0001.jpeg\n",
      "broken img:  IM-0451-0001.jpeg\n",
      "broken img:  IM-0452-0001.jpeg\n",
      "broken img:  IM-0453-0001-0002.jpeg\n",
      "broken img:  IM-0453-0001.jpeg\n",
      "broken img:  IM-0455-0001.jpeg\n",
      "broken img:  IM-0456-0001.jpeg\n",
      "broken img:  IM-0457-0001.jpeg\n",
      "broken img:  IM-0458-0001.jpeg\n",
      "broken img:  IM-0459-0001.jpeg\n",
      "broken img:  IM-0460-0001.jpeg\n",
      "broken img:  IM-0461-0001.jpeg\n",
      "broken img:  IM-0463-0001.jpeg\n",
      "broken img:  IM-0464-0001.jpeg\n",
      "broken img:  IM-0465-0001.jpeg\n",
      "broken img:  IM-0466-0001.jpeg\n",
      "broken img:  IM-0467-0001-0001.jpeg\n",
      "broken img:  IM-0467-0001-0002.jpeg\n",
      "broken img:  IM-0467-0001.jpeg\n",
      "broken img:  IM-0469-0001.jpeg\n",
      "broken img:  IM-0471-0001.jpeg\n",
      "broken img:  IM-0472-0001.jpeg\n",
      "broken img:  IM-0473-0001.jpeg\n",
      "broken img:  IM-0474-0001.jpeg\n",
      "broken img:  IM-0475-0001.jpeg\n",
      "broken img:  IM-0476-0001.jpeg\n",
      "broken img:  IM-0477-0001.jpeg\n",
      "broken img:  IM-0478-0001.jpeg\n",
      "broken img:  IM-0479-0001.jpeg\n",
      "broken img:  IM-0480-0001.jpeg\n",
      "broken img:  IM-0481-0001.jpeg\n",
      "broken img:  IM-0482-0001.jpeg\n",
      "broken img:  IM-0483-0001.jpeg\n",
      "broken img:  IM-0484-0001.jpeg\n",
      "broken img:  IM-0485-0001.jpeg\n",
      "broken img:  IM-0486-0001.jpeg\n",
      "broken img:  IM-0487-0001.jpeg\n",
      "broken img:  IM-0488-0001.jpeg\n",
      "broken img:  IM-0489-0001.jpeg\n",
      "broken img: "
     ]
    }
   ],
   "source": [
    "Data_dir_train = \"./sets/train\"\n",
    "CATEGORIES = [\"NORMAL\", \"PNEUMONIA\"]\n",
    "training_data = []\n",
    "\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES:\n",
    "        path_train = os.path.join(Data_dir_train, category)\n",
    "        class_num = CATEGORIES.index(category)\n",
    "        for img in os.listdir(path_train):\n",
    "            try:\n",
    "                img_array_train = cv2.imread(os.path.join(path_train, img), cv2.IMREAD_GRAYSCALE)\n",
    "                img_array_resized = cv2.resize(img_array_train, (128, 128))\n",
    "                training_data.append([img_array_resized, class_num])\n",
    "            except Exception as e:\n",
    "                print(\"broken img: \", img)\n",
    "                pass\n",
    "    random.shuffle(training_data)\n",
    "    print(len(training_data))\n",
    "    \n",
    "create_training_data()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#check if labeling and shuffling of the data did accure\n",
    "for sample in training_data[:10]:\n",
    "    print(sample[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "    \n",
    "for features, label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "    \n",
    "X = np.array(X).reshape(-1, 128, 128, 1)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "639\n"
     ]
    }
   ],
   "source": [
    "Data_dir_test = \"./sets/test\"\n",
    "CATEGORIES = [\"NORMAL\", \"PNEUMONIA\"]\n",
    "test_data = []\n",
    "\n",
    "def create_testing_data():\n",
    "    for category in CATEGORIES:\n",
    "        path_test = os.path.join(Data_dir_test, category)\n",
    "        class_num = CATEGORIES.index(category)\n",
    "        for img in os.listdir(path_test):\n",
    "            try:\n",
    "                img_array_test = cv2.imread(os.path.join(path_test, img), cv2.IMREAD_GRAYSCALE)\n",
    "                img_array_resized = cv2.resize(img_array_test, (128, 128))\n",
    "                test_data.append([img_array_resized, class_num])\n",
    "            except Exception as e:\n",
    "                print(\"broken img %n\", img)\n",
    "                pass\n",
    "    random.shuffle(test_data)\n",
    "    print(len(test_data))\n",
    "    \n",
    "create_testing_data()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for sample in test_data[:10]:\n",
    "    print(sample[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_UNSEEN = []\n",
    "y_UNSEEN = []\n",
    "    \n",
    "for features, labels in test_data:\n",
    "    X_UNSEEN.append(features)\n",
    "    y_UNSEEN.append(labels)\n",
    "        \n",
    "X_UNSEEN = np.array(X_UNSEEN).reshape(-1, 128, 128, 1)\n",
    "y_UNSEEN = np.array(y_UNSEEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the model\n",
    "recognizer = Sequential()\n",
    "                                                                   \n",
    "#Creating the first 2D convolutional and pooling layer\n",
    "recognizer.add(Convolution2D(filters=64, kernel_size=(3,3), padding='same', activation='relu', kernel_initializer='glorot_uniform', bias_initializer='zeros'))\n",
    "recognizer.add(MaxPooling2D(pool_size=(2,2), padding='same'))                                      \n",
    "                                         \n",
    "#Creating the second 2D convolutional and pooling layer\n",
    "recognizer.add(Convolution2D(filters=128, kernel_size=(3,3), padding='same', activation='relu', kernel_initializer='glorot_uniform', bias_initializer='zeros'))\n",
    "recognizer.add(MaxPooling2D(pool_size=(2,2), padding='same'))                                      \n",
    "                                         \n",
    "#Creating the third 2D convolutional and pooling layer\n",
    "recognizer.add(Convolution2D(filters=256, kernel_size=(3,3), padding='same', activation='relu', kernel_initializer='glorot_uniform', bias_initializer='zeros'))\n",
    "recognizer.add(MaxPooling2D(pool_size=(2,2), padding='same'))\n",
    "        \n",
    "#Transforming the pooling layer into a vector where each vector vlue = neuron\n",
    "recognizer.add(Flatten())\n",
    "        \n",
    "#Creating the Artificial Neural Network\n",
    "recognizer.add(Dense(input_dim = 256, units=128, activation='relu'))\n",
    "recognizer.add(Dense(input_dim =128, units= 64, activation='relu'))\n",
    "recognizer.add(Dense(input_dim =64, units= 1, activation='sigmoid'))\n",
    "\n",
    "#Compiling the Neural Network\n",
    "recognizer.compile(optimizer = \"adam\" , loss=\"binary_crossentropy\" , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"3_conv2D_x_3_dense_256_128_64_adam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = tf.keras.callbacks.TensorBoard(\n",
    "                        log_dir=\"{}\\\\\".format(model_name),\n",
    "                        histogram_freq=0,\n",
    "                        write_graph=True,\n",
    "                        write_images=False,\n",
    "                        update_freq=\"epoch\",\n",
    "                        profile_batch=2,\n",
    "                        embeddings_freq=0,\n",
    "                        embeddings_metadata=None,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X/255.0\n",
    "X_UNSEEN = X_UNSEEN/255.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Value passed to parameter 'input' has DataType uint8 not in list of allowed values: float16, bfloat16, float32, float64, int32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-d95f60060d6a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrecognizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtensorboard\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearn\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearn\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    233\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearn\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[1;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    550\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 552\u001b[1;33m         steps=steps_per_epoch)\n\u001b[0m\u001b[0;32m    553\u001b[0m     (x, y, sample_weights,\n\u001b[0;32m    554\u001b[0m      \u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearn\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2344\u001b[0m     \u001b[1;31m# First, we build the model on the fly if necessary.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2345\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2346\u001b[1;33m       \u001b[0mall_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_model_with_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2347\u001b[0m       \u001b[0mis_build_called\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2348\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearn\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_build_model_with_inputs\u001b[1;34m(self, inputs, targets)\u001b[0m\n\u001b[0;32m   2570\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2571\u001b[0m       \u001b[0mcast_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2572\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2573\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mprocessed_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_dict_inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2574\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearn\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_set_inputs\u001b[1;34m(self, inputs, outputs, training)\u001b[0m\n\u001b[0;32m   2657\u001b[0m           \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'training'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2658\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2659\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2660\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2661\u001b[0m         \u001b[1;31m# This Model or a submodel is dynamic and hasn't overridden\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearn\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    771\u001b[0m                     not base_layer_utils.is_in_eager_or_tf_function()):\n\u001b[0;32m    772\u001b[0m                   \u001b[1;32mwith\u001b[0m \u001b[0mauto_control_deps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAutomaticControlDependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0macd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 773\u001b[1;33m                     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    774\u001b[0m                     \u001b[1;31m# Wrap Tensors in `outputs` in `tf.identity` to avoid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    775\u001b[0m                     \u001b[1;31m# circular dependencies.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearn\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    279\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'training'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 281\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    282\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m       \u001b[1;31m# `outputs` will be the inputs to the next layer.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearn\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    771\u001b[0m                     not base_layer_utils.is_in_eager_or_tf_function()):\n\u001b[0;32m    772\u001b[0m                   \u001b[1;32mwith\u001b[0m \u001b[0mauto_control_deps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAutomaticControlDependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0macd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 773\u001b[1;33m                     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    774\u001b[0m                     \u001b[1;31m# Wrap Tensors in `outputs` in `tf.identity` to avoid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    775\u001b[0m                     \u001b[1;31m# circular dependencies.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearn\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    207\u001b[0m       \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_causal_padding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convolution_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearn\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inp, filter)\u001b[0m\n\u001b[0;32m   1133\u001b[0m           call_from_convolution=False)\n\u001b[0;32m   1134\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;31m# copybara:strip_end\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m     \u001b[1;31m# copybara:insert return self.conv_op(inp, filter)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearn\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inp, filter)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 640\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearn\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inp, filter)\u001b[0m\n\u001b[0;32m    237\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m         name=self.name)\n\u001b[0m\u001b[0;32m    240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearn\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[1;34m(input, filter, strides, padding, use_cudnn_on_gpu, data_format, dilations, name, filters)\u001b[0m\n\u001b[0;32m   2009\u001b[0m                            \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2010\u001b[0m                            \u001b[0mdilations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2011\u001b[1;33m                            name=name)\n\u001b[0m\u001b[0;32m   2012\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2013\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearn\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[1;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[0;32m    967\u001b[0m                   \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    968\u001b[0m                   \u001b[0mexplicit_paddings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexplicit_paddings\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 969\u001b[1;33m                   data_format=data_format, dilations=dilations, name=name)\n\u001b[0m\u001b[0;32m    970\u001b[0m   \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    971\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearn\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    574\u001b[0m             _SatisfiesTypeConstraint(base_type,\n\u001b[0;32m    575\u001b[0m                                      \u001b[0m_Attr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_arg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 576\u001b[1;33m                                      param_name=input_name)\n\u001b[0m\u001b[0;32m    577\u001b[0m           \u001b[0mattrs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattr_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m           \u001b[0minferred_from\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearn\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_SatisfiesTypeConstraint\u001b[1;34m(dtype, attr_def, param_name)\u001b[0m\n\u001b[0;32m     59\u001b[0m           \u001b[1;34m\"allowed values: %s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m           (param_name, dtypes.as_dtype(dtype).name,\n\u001b[1;32m---> 61\u001b[1;33m            \", \".join(dtypes.as_dtype(x).name for x in allowed_list)))\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Value passed to parameter 'input' has DataType uint8 not in list of allowed values: float16, bfloat16, float32, float64, int32"
     ]
    }
   ],
   "source": [
    "recognizer.fit(X, y, batch_size=32, validation_split=0.1, epochs=10, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
