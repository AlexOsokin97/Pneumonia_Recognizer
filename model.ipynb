{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the model:\n",
    "recognizer = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the first 2D convolutional and pooling layer\n",
    "recognizer.add(Convolution2D(filters=32, kernel_size=(3,3), padding='same', activation='relu', kernel_initializer='glorot_uniform', bias_initializer='zeros', input_shape=(256,256,3)))\n",
    "recognizer.add(MaxPooling2D(pool_size=(2,2), padding='same'))                               \n",
    "                                        \n",
    "#Creating the second 2D convolutional and pooling layer\n",
    "recognizer.add(Convolution2D(filters=64, kernel_size=(3,3), padding='same', activation='relu', kernel_initializer='glorot_uniform', bias_initializer='zeros'))\n",
    "recognizer.add(MaxPooling2D(pool_size=(2,2), padding='same'))                                      \n",
    "                                         \n",
    "#Creating the third 2D convolutional and pooling layer\n",
    "recognizer.add(Convolution2D(filters=128, kernel_size=(3,3), padding='same', activation='relu', kernel_initializer='glorot_uniform', bias_initializer='zeros'))\n",
    "recognizer.add(MaxPooling2D(pool_size=(2,2), padding='same'))                                      \n",
    "                                         \n",
    "#Creating the forth 2D convolutional and pooling layer\n",
    "recognizer.add(Convolution2D(filters=256, kernel_size=(3,3), padding='same', activation='relu', kernel_initializer='glorot_uniform', bias_initializer='zeros'))\n",
    "recognizer.add(MaxPooling2D(pool_size=(2,2), padding='same'))\n",
    "        \n",
    "#Transforming the pooling layer into a vector where each vector vlue = neuron\n",
    "recognizer.add(Flatten())\n",
    "        \n",
    "#Creating the Artificial Neural Network\n",
    "recognizer.add(Dense(input_dim = 256, units=128, activation='relu'))\n",
    "recognizer.add(Dense(input_dim =128, units= 128, activation='relu'))\n",
    "recognizer.add(Dense(input_dim =128, units= 64, activation='relu'))\n",
    "recognizer.add(Dense(input_dim =64, units= 1, activation='sigmoid'))\n",
    "\n",
    "#Compiling the Neural Network\n",
    "recognizer.compile(optimizer = \"adagrad\" , loss=\"binary_crossentropy\" , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory('sets/train',\n",
    "                                                  target_size=(256, 256),\n",
    "                                                  batch_size=32,\n",
    "                                                  class_mode='binary') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 639 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "testing_set = test_datagen.flow_from_directory('sets/test',\n",
    "                                                target_size=(256, 256),\n",
    "                                                batch_size=10,\n",
    "                                                class_mode='binary') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = tf.keras.callbacks.TensorBoard(\n",
    "                        log_dir='log\\\\3x4x256x128x128x64',\n",
    "                        histogram_freq=0,\n",
    "                        write_graph=True,\n",
    "                        write_images=False,\n",
    "                        update_freq=\"epoch\",\n",
    "                        profile_batch=2,\n",
    "                        embeddings_freq=0,\n",
    "                        embeddings_metadata=None,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 163 steps, validate for 64 steps\n",
      "Epoch 1/10\n",
      "163/163 [==============================] - 120s 739ms/step - loss: 0.3877 - accuracy: 0.8117 - val_loss: 0.4667 - val_accuracy: 0.8106\n",
      "Epoch 2/10\n",
      "163/163 [==============================] - 122s 750ms/step - loss: 0.2978 - accuracy: 0.8652 - val_loss: 0.4128 - val_accuracy: 0.8404\n",
      "Epoch 3/10\n",
      "163/163 [==============================] - 121s 745ms/step - loss: 0.2794 - accuracy: 0.8771 - val_loss: 0.3917 - val_accuracy: 0.8357\n",
      "Epoch 4/10\n",
      "163/163 [==============================] - 121s 743ms/step - loss: 0.2697 - accuracy: 0.8819 - val_loss: 0.3262 - val_accuracy: 0.8858\n",
      "Epoch 5/10\n",
      "163/163 [==============================] - 122s 746ms/step - loss: 0.2536 - accuracy: 0.8915 - val_loss: 0.3055 - val_accuracy: 0.8873\n",
      "Epoch 6/10\n",
      "163/163 [==============================] - 122s 750ms/step - loss: 0.2416 - accuracy: 0.8982 - val_loss: 0.3154 - val_accuracy: 0.8967\n",
      "Epoch 7/10\n",
      "163/163 [==============================] - 122s 751ms/step - loss: 0.2318 - accuracy: 0.9066 - val_loss: 0.2765 - val_accuracy: 0.8936\n",
      "Epoch 8/10\n",
      "163/163 [==============================] - 122s 749ms/step - loss: 0.2334 - accuracy: 0.9051 - val_loss: 0.3722 - val_accuracy: 0.8310\n",
      "Epoch 9/10\n",
      "163/163 [==============================] - 121s 742ms/step - loss: 0.2176 - accuracy: 0.9132 - val_loss: 0.4270 - val_accuracy: 0.8153\n",
      "Epoch 10/10\n",
      "163/163 [==============================] - 121s 745ms/step - loss: 0.2190 - accuracy: 0.9118 - val_loss: 0.3754 - val_accuracy: 0.8466\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ed54936e10>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recognizer.fit(\n",
    "            training_set,\n",
    "            epochs=10,\n",
    "            callbacks=[tensorboard],\n",
    "            validation_data=testing_set,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
