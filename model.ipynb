{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the model:\n",
    "recognizer = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the first 2D convolutional and pooling layer\n",
    "recognizer.add(Convolution2D(filters=32, kernel_size=(3,3), padding='same', activation='relu',\n",
    "                             kernel_initializer='glorot_uniform', bias_initializer='zeros', input_shape=(256,256,3)))\n",
    "recognizer.add(MaxPooling2D(pool_size=(2,2), padding='same'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the second 2D convolutional and pooling layer\n",
    "recognizer.add(Convolution2D(filters=64, kernel_size=(3,3), padding='same', activation='relu',\n",
    "                             kernel_initializer='glorot_uniform', bias_initializer='zeros'))\n",
    "recognizer.add(MaxPooling2D(pool_size=(2,2), padding='same'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the third 2D convolutional and pooling layer\n",
    "recognizer.add(Convolution2D(filters=128, kernel_size=(3,3), padding='same', activation='relu',\n",
    "                             kernel_initializer='glorot_uniform', bias_initializer='zeros'))\n",
    "recognizer.add(MaxPooling2D(pool_size=(2,2), padding='same'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the forth 2D convolutional and pooling layer\n",
    "recognizer.add(Convolution2D(filters=256, kernel_size=(3,3), padding='same', activation='relu',\n",
    "                             kernel_initializer='glorot_uniform', bias_initializer='zeros'))\n",
    "recognizer.add(MaxPooling2D(pool_size=(2,2), padding='same'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforming the pooling layer into a vector where each vector vlue = neuron\n",
    "recognizer.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the Artificial Neural Network\n",
    "recognizer.add(Dense(input_dim = 256, units=128, activation='relu'))\n",
    "recognizer.add(Dense(input_dim =128, units= 128, activation='relu'))\n",
    "recognizer.add(Dense(input_dim =128, units= 128, activation='relu'))\n",
    "recognizer.add(Dense(input_dim =128, units= 1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling the Neural Network\n",
    "recognizer.compile(optimizer = \"adagrad\" , loss=\"binary_crossentropy\" , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before continuing to training my model, applying k-folds and fitting on the test set I wanted make sure that my model has the abillity to overfit. The reason is to make sure that my data has enough features for the model to learn from and that my model extracts enough features to learn from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Documents\\GitHub\\Pneumonia_Recognizer\n"
     ]
    }
   ],
   "source": [
    "path = os.path.abspath(os.getcwd())\n",
    "#image = load_img('sets/val')\n",
    "#input_arr = img_to_array(image)\n",
    "#input_arr = np.array([input_arr])  # Convert single image to a batch.\n",
    "#predictions = recognizer.fit(input_arr)\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_gen = ImageDataGenerator(rescale=1./255)\n",
    "val_set = val_gen.flow_from_directory(\n",
    "                                       target_size=(256, 256),\n",
    "                                       batch_size=1,\n",
    "                                       class_mode='binary')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "                                    \n",
    "training_set = train_datagen.flow_from_directory('sets/train',\n",
    "                                                  target_size=(256, 256),\n",
    "                                                  batch_size=20,\n",
    "                                                  class_mode='binary') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "testing_set = test_datagen.flow_from_directory('sets/validation',\n",
    "                                                   target_size=(256, 256),\n",
    "                                                   batch_size=2,\n",
    "                                                   class_mode='binary')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
